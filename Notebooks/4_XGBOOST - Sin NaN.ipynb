{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pylab import rcParams\n",
    " \n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.ensemble import BalancedBaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('dataset_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=df[['temp_media',\n",
    "       'temp_max_med', 'temp_min_med', 'prec_acu', 'hum_med', \n",
    "        'v_viento_med', 'lluvia', 'helada','lume']]\n",
    "z=z.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['explained_variance', 'r2', 'max_error', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_absolute_percentage_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_root_mean_squared_error', 'neg_mean_poisson_deviance', 'neg_mean_gamma_deviance', 'accuracy', 'top_k_accuracy', 'roc_auc', 'roc_auc_ovr', 'roc_auc_ovo', 'roc_auc_ovr_weighted', 'roc_auc_ovo_weighted', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'neg_brier_score', 'adjusted_rand_score', 'rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.metrics.SCORERS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=z[['temp_media',\n",
    "       'temp_max_med', 'temp_min_med', 'prec_acu', 'hum_med', \n",
    "        'v_viento_med', 'lluvia', 'helada']]\n",
    "y=z['lume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((989527, 8), (989527,), (212042, 8), (212042,), (212042, 8))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = xgboost.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={'nthreads':[1],\n",
    "            'objective':['binary:logistic'],\n",
    "            'learning_rate': [0.05, 0.1],\n",
    "            'n_estimators': [100,200]\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params = {'early_stopping_rounds': 10,\n",
    "             'eval_metric': 'logloss',\n",
    "             'eval_set': [(X_test, y_test)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(xgb, parameters, cv=3, scoring='recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:40:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:40:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:40:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:40:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:41:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:41:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:42:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:42:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:43:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:43:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:45:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:45:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:46:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:46:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:47:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:47:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:48:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:48:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:49:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:49:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:50:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:50:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:52:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:52:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:53:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:53:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, random_state=None,\n",
       "                                     reg_alpha=None, reg_lambda=None,\n",
       "                                     scale_pos_weight=None, subsample=None,\n",
       "                                     tree_method=None, validate_parameters=None,\n",
       "                                     verbosity=None),\n",
       "             param_grid={'learning_rate': [0.05, 0.1],\n",
       "                         'n_estimators': [100, 200], 'nthreads': [1],\n",
       "                         'objective': ['binary:logistic']},\n",
       "             scoring='recall')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgb = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_preds = best_xgb.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    209480\n",
      "           1       0.00      0.00      0.00      2562\n",
      "\n",
      "    accuracy                           0.99    212042\n",
      "   macro avg       0.49      0.50      0.50    212042\n",
      "weighted avg       0.98      0.99      0.98    212042\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos ahora con los datos balanceados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "os =  RandomOverSampler(sampling_strategy='minority')\n",
    "X_train_res, y_train_res = os.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:05:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:05:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:07:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:07:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:08:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:08:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:10:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:10:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:14:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:14:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:18:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:18:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:22:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:22:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:24:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:24:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:27:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:27:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:29:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:29:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:32:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:32:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:36:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:36:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:40:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:40:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, random_state=None,\n",
       "                                     reg_alpha=None, reg_lambda=None,\n",
       "                                     scale_pos_weight=None, subsample=None,\n",
       "                                     tree_method=None, validate_parameters=None,\n",
       "                                     verbosity=None),\n",
       "             param_grid={'learning_rate': [0.05, 0.1],\n",
       "                         'n_estimators': [100, 200], 'nthreads': [1],\n",
       "                         'objective': ['binary:logistic']},\n",
       "             scoring='recall')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=200, n_jobs=4, nthreads=1, num_parallel_tree=1,\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_xgb_balanced = clf.best_estimator_\n",
    "best_xgb_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7920979145437972"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_preds_balanced = best_xgb_balanced.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.76      0.86    279343\n",
      "           1       0.04      0.74      0.07      3380\n",
      "\n",
      "    accuracy                           0.76    282723\n",
      "   macro avg       0.52      0.75      0.46    282723\n",
      "weighted avg       0.98      0.76      0.85    282723\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_preds_balanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.76      0.86    279343\n",
      "           1       0.04      0.74      0.07      3380\n",
      "\n",
      "    accuracy                           0.76    282723\n",
      "   macro avg       0.52      0.75      0.46    282723\n",
      "weighted avg       0.98      0.76      0.85    282723\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "def mostrar_resultados(y_test, pred_y):\n",
    "    conf_matrix = confusion_matrix(y_test, pred_y)\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    sns.heatmap(conf_matrix, xticklabels=2, yticklabels=2, annot=True, fmt=\"d\");\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.ylabel('True class')\n",
    "    plt.xlabel('Predicted class')\n",
    "    plt.show()\n",
    "    print (classification_report(y_test, pred_y))\n",
    "mostrar_resultados(y_test, y_preds_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       1.00      0.76      0.86    279343\\n           1       0.04      0.74      0.07      3380\\n\\n    accuracy                           0.76    282723\\n   macro avg       0.52      0.75      0.46    282723\\nweighted avg       0.98      0.76      0.85    282723\\n'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(y_test, y_preds_balanced)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
