{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pylab import rcParams\n",
    " \n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.ensemble import BalancedBaggingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carga de datos con Embalses y rios\n",
    "df=pd.read_csv('datos_rios_embalses_tiempo.csv',index_col=[0])\n",
    "\n",
    "tiempo=pd.read_excel('tiempo.xlsx')\n",
    "tiempo.columns = map(lambda x: str(x).lower(), tiempo.columns) \n",
    "tiempo['provincia'] = tiempo['provincia'].str.upper() \n",
    "tiempo['estación'] = tiempo['estación'].str.upper() \n",
    "\n",
    "#inclusión del código de la provincia:\n",
    "tiempo['idprovincia'] = tiempo['provincia'].apply(lambda x: 15 if x=='A CORUÑA' else (32 if x=='OURENSE' else (27 if x=='LUGO' else 36)))\n",
    "#inclusión del mes-año\n",
    "tiempo['fecha']=tiempo['fecha'].astype(str)\n",
    "tiempo['mes']=tiempo['fecha'].str[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función distancias mínimas\n",
    "\n",
    "from math import radians, cos, sin, asin, sqrt \n",
    "def distance(lat1, lat2, lon1, lon2): \n",
    "      \n",
    "    # radians which converts from degrees to radians. \n",
    "    lon1 = radians(lon1) \n",
    "    lon2 = radians(lon2) \n",
    "    lat1 = radians(lat1) \n",
    "    lat2 = radians(lat2) \n",
    "       \n",
    "    # Haversine formula  \n",
    "    dlon = lon2 - lon1  \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "  \n",
    "    c = 2 * asin(sqrt(a))  \n",
    "     \n",
    "    # Radius of earth in kilometers. Use 3956 for miles \n",
    "    r = 6371\n",
    "       \n",
    "    # calculate the result \n",
    "    return(c * r) \n",
    "\n",
    "def dist_min(df1,column_lat1,column_lat2,column_lng1,column_lng2,index,name):\n",
    "    \n",
    "    #Add column containing distances \n",
    "    df1[name]=df1.apply(lambda x: distance(x[column_lat1], x[column_lat2], x[column_lng1], x[column_lng2]), axis=1)\n",
    "    #Selecting the min distance per id\n",
    "    df1_min = df1.groupby([index]).agg({name: 'min'})\n",
    "    df2 = pd.merge(df1, df1_min, on = index, how ='inner')\n",
    "    df = df2[(df2[name+'_x']==df2[name+'_y']) | df2[name+'_x'].isna()]\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-9f62b0560cb2>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  inc_totales['coord']=list(zip(inc_totales.lat, inc_totales.lng))\n"
     ]
    }
   ],
   "source": [
    "# Incendios totales\n",
    "inc_totales=df[['id','mes','idprovincia','lat','lng']]\n",
    "inc_totales['coord']=list(zip(inc_totales.lat, inc_totales.lng))\n",
    "inc_totales=inc_totales.reset_index()\n",
    "\n",
    "#Localización única de incendios\n",
    "localizacion_inc_unic=inc_totales[['coord','lat','lng','idprovincia']].drop_duplicates().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mes: 2001-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-94ffad726182>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  noinc_i['mes']=i\n",
      "<ipython-input-5-94ffad726182>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  noinc_i['lume']=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mes: 2001-04\n",
      "Mes: 2001-05\n",
      "Mes: 2001-06\n",
      "Mes: 2001-07\n",
      "Mes: 2001-08\n",
      "Mes: 2001-09\n",
      "Mes: 2001-11\n",
      "Mes: 2001-12\n",
      "Mes: 2002-02\n",
      "Mes: 2002-03\n",
      "Mes: 2002-04\n",
      "Mes: 2002-05\n",
      "Mes: 2002-06\n",
      "Mes: 2002-07\n",
      "Mes: 2002-08\n",
      "Mes: 2002-09\n",
      "Mes: 2002-10\n",
      "Mes: 2003-01\n",
      "Mes: 2003-02\n",
      "Mes: 2003-03\n",
      "Mes: 2003-04\n",
      "Mes: 2003-05\n",
      "Mes: 2003-06\n",
      "Mes: 2003-07\n",
      "Mes: 2003-08\n",
      "Mes: 2003-09\n",
      "Mes: 2003-10\n",
      "Mes: 2003-11\n",
      "Mes: 2004-02\n",
      "Mes: 2004-03\n",
      "Mes: 2004-04\n",
      "Mes: 2004-05\n",
      "Mes: 2004-06\n",
      "Mes: 2004-07\n",
      "Mes: 2004-08\n",
      "Mes: 2004-09\n",
      "Mes: 2004-10\n",
      "Mes: 2004-11\n",
      "Mes: 2004-12\n",
      "Mes: 2005-01\n",
      "Mes: 2005-02\n",
      "Mes: 2005-03\n",
      "Mes: 2005-04\n",
      "Mes: 2005-05\n",
      "Mes: 2005-06\n",
      "Mes: 2005-07\n",
      "Mes: 2005-08\n",
      "Mes: 2005-09\n",
      "Mes: 2005-10\n",
      "Mes: 2005-12\n",
      "Mes: 2006-01\n",
      "Mes: 2006-02\n",
      "Mes: 2006-03\n",
      "Mes: 2006-04\n",
      "Mes: 2006-05\n",
      "Mes: 2006-06\n",
      "Mes: 2006-07\n",
      "Mes: 2006-08\n",
      "Mes: 2006-09\n",
      "Mes: 2006-11\n",
      "Mes: 2006-12\n",
      "Mes: 2007-02\n",
      "Mes: 2007-03\n",
      "Mes: 2007-04\n",
      "Mes: 2007-05\n",
      "Mes: 2007-06\n",
      "Mes: 2007-07\n",
      "Mes: 2007-08\n",
      "Mes: 2007-09\n",
      "Mes: 2007-10\n",
      "Mes: 2007-11\n",
      "Mes: 2007-12\n",
      "Mes: 2008-01\n",
      "Mes: 2008-02\n",
      "Mes: 2008-03\n",
      "Mes: 2008-04\n",
      "Mes: 2008-05\n",
      "Mes: 2008-06\n",
      "Mes: 2008-07\n",
      "Mes: 2008-08\n",
      "Mes: 2008-09\n",
      "Mes: 2008-10\n",
      "Mes: 2008-12\n",
      "Mes: 2009-02\n",
      "Mes: 2009-03\n",
      "Mes: 2009-04\n",
      "Mes: 2009-05\n",
      "Mes: 2009-06\n",
      "Mes: 2009-07\n",
      "Mes: 2009-08\n",
      "Mes: 2009-09\n",
      "Mes: 2009-10\n",
      "Mes: 2009-12\n",
      "Mes: 2010-02\n",
      "Mes: 2010-03\n",
      "Mes: 2010-04\n",
      "Mes: 2010-05\n",
      "Mes: 2010-06\n",
      "Mes: 2010-07\n",
      "Mes: 2010-08\n",
      "Mes: 2010-09\n",
      "Mes: 2010-10\n",
      "Mes: 2010-11\n",
      "Mes: 2011-01\n",
      "Mes: 2011-02\n",
      "Mes: 2011-03\n",
      "Mes: 2011-04\n",
      "Mes: 2011-05\n",
      "Mes: 2011-06\n",
      "Mes: 2011-07\n",
      "Mes: 2011-08\n",
      "Mes: 2011-09\n",
      "Mes: 2011-10\n",
      "Mes: 2011-12\n",
      "Mes: 2012-02\n",
      "Mes: 2012-03\n",
      "Mes: 2012-04\n",
      "Mes: 2012-05\n",
      "Mes: 2012-06\n",
      "Mes: 2012-07\n",
      "Mes: 2012-08\n",
      "Mes: 2012-09\n",
      "Mes: 2012-10\n",
      "Mes: 2013-03\n",
      "Mes: 2013-04\n",
      "Mes: 2013-05\n",
      "Mes: 2013-06\n",
      "Mes: 2013-07\n",
      "Mes: 2013-08\n",
      "Mes: 2013-09\n",
      "Mes: 2013-10\n",
      "Mes: 2013-11\n",
      "Mes: 2013-12\n",
      "Mes: 2014-03\n",
      "Mes: 2014-04\n",
      "Mes: 2014-05\n",
      "Mes: 2014-06\n",
      "Mes: 2014-07\n",
      "Mes: 2014-08\n",
      "Mes: 2014-09\n",
      "Mes: 2014-10\n",
      "Mes: 2015-03\n",
      "Mes: 2015-04\n",
      "Mes: 2015-05\n",
      "Mes: 2015-06\n",
      "Mes: 2015-07\n",
      "Mes: 2015-08\n",
      "Mes: 2015-09\n",
      "Mes: 2015-10\n",
      "Mes: 2015-11\n",
      "Mes: 2015-12\n",
      "Mes: 2001-03\n",
      "Mes: 2001-10\n",
      "Mes: 2002-01\n",
      "Mes: 2003-12\n",
      "Mes: 2004-01\n",
      "Mes: 2005-11\n",
      "Mes: 2007-01\n",
      "Mes: 2009-11\n",
      "Mes: 2011-11\n",
      "Mes: 2012-01\n",
      "Mes: 2012-11\n",
      "Mes: 2015-01\n",
      "Mes: 2008-11\n",
      "Mes: 2009-01\n",
      "Mes: 2010-01\n",
      "Mes: 2010-12\n",
      "Mes: 2012-12\n",
      "Mes: 2013-01\n",
      "Mes: 2013-02\n",
      "Mes: 2014-12\n",
      "Mes: 2015-02\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mes</th>\n",
       "      <th>idprovincia</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>coord</th>\n",
       "      <th>lume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001-02</td>\n",
       "      <td>15</td>\n",
       "      <td>43.703581</td>\n",
       "      <td>-8.038777</td>\n",
       "      <td>(43.703581, -8.038777)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001-02</td>\n",
       "      <td>15</td>\n",
       "      <td>42.936918</td>\n",
       "      <td>-9.114350</td>\n",
       "      <td>(42.936918, -9.11435)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-02</td>\n",
       "      <td>15</td>\n",
       "      <td>42.643031</td>\n",
       "      <td>-8.939252</td>\n",
       "      <td>(42.643031, -8.939252)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001-02</td>\n",
       "      <td>15</td>\n",
       "      <td>43.186836</td>\n",
       "      <td>-8.685470</td>\n",
       "      <td>(43.186836, -8.68547)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001-02</td>\n",
       "      <td>15</td>\n",
       "      <td>42.917476</td>\n",
       "      <td>-9.082862</td>\n",
       "      <td>(42.917476, -9.082861999999999)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11795</th>\n",
       "      <td>2015-02</td>\n",
       "      <td>36</td>\n",
       "      <td>42.103959</td>\n",
       "      <td>-8.522512</td>\n",
       "      <td>(42.10395894, -8.52251246)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11796</th>\n",
       "      <td>2015-02</td>\n",
       "      <td>36</td>\n",
       "      <td>42.157695</td>\n",
       "      <td>-8.397080</td>\n",
       "      <td>(42.15769512, -8.39708026)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11797</th>\n",
       "      <td>2015-02</td>\n",
       "      <td>36</td>\n",
       "      <td>42.554722</td>\n",
       "      <td>-8.018586</td>\n",
       "      <td>(42.55472219, -8.01858582)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11798</th>\n",
       "      <td>2015-02</td>\n",
       "      <td>36</td>\n",
       "      <td>42.243441</td>\n",
       "      <td>-8.322375</td>\n",
       "      <td>(42.24344138, -8.32237515)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11799</th>\n",
       "      <td>2015-02</td>\n",
       "      <td>36</td>\n",
       "      <td>42.658303</td>\n",
       "      <td>-8.268949</td>\n",
       "      <td>(42.65830287, -8.26894924)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2046302 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           mes  idprovincia        lat       lng  \\\n",
       "0      2001-02           15  43.703581 -8.038777   \n",
       "1      2001-02           15  42.936918 -9.114350   \n",
       "2      2001-02           15  42.643031 -8.939252   \n",
       "3      2001-02           15  43.186836 -8.685470   \n",
       "4      2001-02           15  42.917476 -9.082862   \n",
       "...        ...          ...        ...       ...   \n",
       "11795  2015-02           36  42.103959 -8.522512   \n",
       "11796  2015-02           36  42.157695 -8.397080   \n",
       "11797  2015-02           36  42.554722 -8.018586   \n",
       "11798  2015-02           36  42.243441 -8.322375   \n",
       "11799  2015-02           36  42.658303 -8.268949   \n",
       "\n",
       "                                 coord  lume  \n",
       "0               (43.703581, -8.038777)     1  \n",
       "1                (42.936918, -9.11435)     1  \n",
       "2               (42.643031, -8.939252)     1  \n",
       "3                (43.186836, -8.68547)     1  \n",
       "4      (42.917476, -9.082861999999999)     1  \n",
       "...                                ...   ...  \n",
       "11795       (42.10395894, -8.52251246)     0  \n",
       "11796       (42.15769512, -8.39708026)     0  \n",
       "11797       (42.55472219, -8.01858582)     0  \n",
       "11798       (42.24344138, -8.32237515)     0  \n",
       "11799       (42.65830287, -8.26894924)     0  \n",
       "\n",
       "[2046302 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inc=pd.DataFrame()\n",
    "for i in inc_totales['mes'].unique():\n",
    "    print('Mes: '+str(i))\n",
    "    #Inclusión de los incendios del mes i\n",
    "    inc_i=inc_totales[inc_totales['mes']==i][['mes','idprovincia','lat','lng','coord']]\n",
    "    inc_i['lume']=1\n",
    "    \n",
    "    inc=inc.append(inc_i)\n",
    "    \n",
    "    #Inclusión de los NO incendios del mes i\n",
    "    index_noinc=np.vectorize(lambda t: t not in inc_totales[inc_totales['mes']==i]['coord'].tolist())\n",
    "    noinc_i=localizacion_inc_unic[index_noinc(localizacion_inc_unic['coord'])]\n",
    "    noinc_i['mes']=i\n",
    "    noinc_i['lume']=0\n",
    "    \n",
    "    inc=inc.append(noinc_i[['mes','idprovincia','lat','lng','coord','lume']])\n",
    "\n",
    "inc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc=inc.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc=inc.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>mes</th>\n",
       "      <th>idprovincia</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>coord</th>\n",
       "      <th>lume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2001-02</td>\n",
       "      <td>15</td>\n",
       "      <td>43.703581</td>\n",
       "      <td>-8.038777</td>\n",
       "      <td>(43.703581, -8.038777)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2001-02</td>\n",
       "      <td>15</td>\n",
       "      <td>42.936918</td>\n",
       "      <td>-9.114350</td>\n",
       "      <td>(42.936918, -9.11435)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2001-02</td>\n",
       "      <td>15</td>\n",
       "      <td>42.643031</td>\n",
       "      <td>-8.939252</td>\n",
       "      <td>(42.643031, -8.939252)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2001-02</td>\n",
       "      <td>15</td>\n",
       "      <td>43.186836</td>\n",
       "      <td>-8.685470</td>\n",
       "      <td>(43.186836, -8.68547)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2001-02</td>\n",
       "      <td>15</td>\n",
       "      <td>42.917476</td>\n",
       "      <td>-9.082862</td>\n",
       "      <td>(42.917476, -9.082861999999999)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046297</th>\n",
       "      <td>2046297</td>\n",
       "      <td>11795</td>\n",
       "      <td>2015-02</td>\n",
       "      <td>36</td>\n",
       "      <td>42.103959</td>\n",
       "      <td>-8.522512</td>\n",
       "      <td>(42.10395894, -8.52251246)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046298</th>\n",
       "      <td>2046298</td>\n",
       "      <td>11796</td>\n",
       "      <td>2015-02</td>\n",
       "      <td>36</td>\n",
       "      <td>42.157695</td>\n",
       "      <td>-8.397080</td>\n",
       "      <td>(42.15769512, -8.39708026)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046299</th>\n",
       "      <td>2046299</td>\n",
       "      <td>11797</td>\n",
       "      <td>2015-02</td>\n",
       "      <td>36</td>\n",
       "      <td>42.554722</td>\n",
       "      <td>-8.018586</td>\n",
       "      <td>(42.55472219, -8.01858582)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046300</th>\n",
       "      <td>2046300</td>\n",
       "      <td>11798</td>\n",
       "      <td>2015-02</td>\n",
       "      <td>36</td>\n",
       "      <td>42.243441</td>\n",
       "      <td>-8.322375</td>\n",
       "      <td>(42.24344138, -8.32237515)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046301</th>\n",
       "      <td>2046301</td>\n",
       "      <td>11799</td>\n",
       "      <td>2015-02</td>\n",
       "      <td>36</td>\n",
       "      <td>42.658303</td>\n",
       "      <td>-8.268949</td>\n",
       "      <td>(42.65830287, -8.26894924)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2046302 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         level_0  index      mes  idprovincia        lat       lng  \\\n",
       "0              0      0  2001-02           15  43.703581 -8.038777   \n",
       "1              1      1  2001-02           15  42.936918 -9.114350   \n",
       "2              2      2  2001-02           15  42.643031 -8.939252   \n",
       "3              3      3  2001-02           15  43.186836 -8.685470   \n",
       "4              4      4  2001-02           15  42.917476 -9.082862   \n",
       "...          ...    ...      ...          ...        ...       ...   \n",
       "2046297  2046297  11795  2015-02           36  42.103959 -8.522512   \n",
       "2046298  2046298  11796  2015-02           36  42.157695 -8.397080   \n",
       "2046299  2046299  11797  2015-02           36  42.554722 -8.018586   \n",
       "2046300  2046300  11798  2015-02           36  42.243441 -8.322375   \n",
       "2046301  2046301  11799  2015-02           36  42.658303 -8.268949   \n",
       "\n",
       "                                   coord  lume  \n",
       "0                 (43.703581, -8.038777)     1  \n",
       "1                  (42.936918, -9.11435)     1  \n",
       "2                 (42.643031, -8.939252)     1  \n",
       "3                  (43.186836, -8.68547)     1  \n",
       "4        (42.917476, -9.082861999999999)     1  \n",
       "...                                  ...   ...  \n",
       "2046297       (42.10395894, -8.52251246)     0  \n",
       "2046298       (42.15769512, -8.39708026)     0  \n",
       "2046299       (42.55472219, -8.01858582)     0  \n",
       "2046300       (42.24344138, -8.32237515)     0  \n",
       "2046301       (42.65830287, -8.26894924)     0  \n",
       "\n",
       "[2046302 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mes 2001-02\n",
      "mes 2001-03\n",
      "mes 2001-04\n",
      "mes 2001-05\n",
      "mes 2001-06\n",
      "mes 2001-07\n",
      "mes 2001-08\n",
      "mes 2001-09\n",
      "mes 2001-10\n",
      "mes 2001-11\n",
      "mes 2001-12\n",
      "mes 2002-01\n",
      "mes 2002-02\n",
      "mes 2002-03\n",
      "mes 2002-04\n",
      "mes 2002-05\n",
      "mes 2002-06\n",
      "mes 2002-07\n",
      "mes 2002-08\n",
      "mes 2002-09\n",
      "mes 2002-10\n",
      "mes 2003-01\n",
      "mes 2003-02\n",
      "mes 2003-03\n",
      "mes 2003-04\n",
      "mes 2003-05\n",
      "mes 2003-06\n",
      "mes 2003-07\n",
      "mes 2003-08\n",
      "mes 2003-09\n",
      "mes 2003-10\n",
      "mes 2003-11\n",
      "mes 2003-12\n",
      "mes 2004-01\n",
      "mes 2004-02\n",
      "mes 2004-03\n",
      "mes 2004-04\n",
      "mes 2004-05\n",
      "mes 2004-06\n",
      "mes 2004-07\n",
      "mes 2004-08\n",
      "mes 2004-09\n",
      "mes 2004-10\n",
      "mes 2004-11\n",
      "mes 2004-12\n",
      "mes 2005-01\n",
      "mes 2005-02\n",
      "mes 2005-03\n",
      "mes 2005-04\n",
      "mes 2005-05\n",
      "mes 2005-06\n",
      "mes 2005-07\n",
      "mes 2005-08\n",
      "mes 2005-09\n",
      "mes 2005-10\n",
      "mes 2005-11\n",
      "mes 2005-12\n",
      "mes 2006-01\n",
      "mes 2006-02\n",
      "mes 2006-03\n",
      "mes 2006-04\n",
      "mes 2006-05\n",
      "mes 2006-06\n",
      "mes 2006-07\n",
      "mes 2006-08\n",
      "mes 2006-09\n",
      "mes 2006-11\n",
      "mes 2006-12\n",
      "mes 2007-01\n",
      "mes 2007-02\n",
      "mes 2007-03\n",
      "mes 2007-04\n",
      "mes 2007-05\n",
      "mes 2007-06\n",
      "mes 2007-07\n",
      "mes 2007-08\n",
      "mes 2007-09\n",
      "mes 2007-10\n",
      "mes 2007-11\n",
      "mes 2007-12\n",
      "mes 2008-01\n",
      "mes 2008-02\n",
      "mes 2008-03\n",
      "mes 2008-04\n",
      "mes 2008-05\n",
      "mes 2008-06\n",
      "mes 2008-07\n",
      "mes 2008-08\n",
      "mes 2008-09\n",
      "mes 2008-10\n",
      "mes 2008-11\n",
      "mes 2008-12\n",
      "mes 2009-01\n",
      "mes 2009-02\n",
      "mes 2009-03\n",
      "mes 2009-04\n",
      "mes 2009-05\n",
      "mes 2009-06\n",
      "mes 2009-07\n",
      "mes 2009-08\n",
      "mes 2009-09\n",
      "mes 2009-10\n",
      "mes 2009-11\n",
      "mes 2009-12\n",
      "mes 2010-01\n",
      "mes 2010-02\n",
      "mes 2010-03\n",
      "mes 2010-04\n",
      "mes 2010-05\n",
      "mes 2010-06\n",
      "mes 2010-07\n",
      "mes 2010-08\n",
      "mes 2010-09\n",
      "mes 2010-10\n",
      "mes 2010-11\n",
      "mes 2010-12\n",
      "mes 2011-01\n",
      "mes 2011-02\n",
      "mes 2011-03\n",
      "mes 2011-04\n",
      "mes 2011-05\n",
      "mes 2011-06\n",
      "mes 2011-07\n",
      "mes 2011-08\n",
      "mes 2011-09\n",
      "mes 2011-10\n",
      "mes 2011-11\n",
      "mes 2011-12\n",
      "mes 2012-01\n",
      "mes 2012-02\n",
      "mes 2012-03\n",
      "mes 2012-04\n",
      "mes 2012-05\n",
      "mes 2012-06\n",
      "mes 2012-07\n",
      "mes 2012-08\n",
      "mes 2012-09\n",
      "mes 2012-10\n",
      "mes 2012-11\n",
      "mes 2012-12\n",
      "mes 2013-01\n",
      "mes 2013-02\n",
      "mes 2013-03\n",
      "mes 2013-04\n",
      "mes 2013-05\n",
      "mes 2013-06\n",
      "mes 2013-07\n",
      "mes 2013-08\n",
      "mes 2013-09\n",
      "mes 2013-10\n",
      "mes 2013-11\n",
      "mes 2013-12\n",
      "mes 2014-03\n",
      "mes 2014-04\n",
      "mes 2014-05\n",
      "mes 2014-06\n",
      "mes 2014-07\n",
      "mes 2014-08\n",
      "mes 2014-09\n",
      "mes 2014-10\n",
      "mes 2014-12\n",
      "mes 2015-01\n",
      "mes 2015-02\n",
      "mes 2015-03\n",
      "mes 2015-04\n",
      "mes 2015-05\n",
      "mes 2015-06\n",
      "mes 2015-07\n",
      "mes 2015-08\n",
      "mes 2015-09\n",
      "mes 2015-10\n",
      "mes 2015-11\n",
      "mes 2015-12\n"
     ]
    }
   ],
   "source": [
    "df_inc_tiempo=pd.DataFrame()\n",
    "\n",
    "for i in np.sort(inc['mes'].unique()):\n",
    "    print('mes ' +i)\n",
    "    dfi=pd.merge(inc[inc['mes']==i], tiempo[tiempo['mes']==i], on=['idprovincia', 'mes'], how='inner')\n",
    "    dfi = dist_min(dfi, 'lat', 'latitud', 'lng', 'longitud', 'level_0','dist_est')\n",
    "    df_inc_tiempo=pd.concat([df_inc_tiempo,dfi], axis=0)\n",
    "\n",
    "z=df_inc_tiempo[[ 'temp_media',\n",
    "       'temp_max_med', 'temp_min_med', 'prec_acu', 'hum_med', 'hum_max',\n",
    "       'hum_min', 'v_viento_med', 'presion', 'lluvia', 'helada','lume']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.to_csv('tiempo_lume.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=z[[ 'temp_media',\n",
    "       'temp_max_med', 'temp_min_med', 'prec_acu', 'hum_med', 'hum_max',\n",
    "       'hum_min', 'v_viento_med', 'presion', 'lluvia', 'helada']]\n",
    "y=z['lume']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['explained_variance', 'r2', 'max_error', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_absolute_percentage_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_root_mean_squared_error', 'neg_mean_poisson_deviance', 'neg_mean_gamma_deviance', 'accuracy', 'top_k_accuracy', 'roc_auc', 'roc_auc_ovr', 'roc_auc_ovo', 'roc_auc_ovr_weighted', 'roc_auc_ovo_weighted', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'neg_brier_score', 'adjusted_rand_score', 'rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.metrics.SCORERS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = xgboost.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={'nthreads':[1],\n",
    "            'objective':['binary:logistic'],\n",
    "            'learning_rate': [0.05, 0.1],\n",
    "            'n_estimators': [100,200]\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(xgb, parameters, cv=3, scoring='recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:39:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[09:39:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:42:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[09:42:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:44:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[09:44:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:47:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[09:47:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:52:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[09:52:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:57:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[09:57:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:02:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[10:03:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:05:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[10:05:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:08:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[10:08:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:10:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[10:10:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:16:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[10:16:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:21:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[10:21:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:26:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[10:26:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, random_state=None,\n",
       "                                     reg_alpha=None, reg_lambda=None,\n",
       "                                     scale_pos_weight=None, subsample=None,\n",
       "                                     tree_method=None, validate_parameters=None,\n",
       "                                     verbosity=None),\n",
       "             param_grid={'learning_rate': [0.05, 0.1],\n",
       "                         'n_estimators': [100, 200], 'nthreads': [1],\n",
       "                         'objective': ['binary:logistic']},\n",
       "             scoring='recall')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgb = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_preds = best_xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    404477\n",
      "           1       0.00      0.00      0.00      4784\n",
      "\n",
      "    accuracy                           0.99    409261\n",
      "   macro avg       0.49      0.50      0.50    409261\n",
      "weighted avg       0.98      0.99      0.98    409261\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    404477\n",
      "           1       0.00      0.00      0.00      4784\n",
      "\n",
      "    accuracy                           0.99    409261\n",
      "   macro avg       0.49      0.50      0.50    409261\n",
      "weighted avg       0.98      0.99      0.98    409261\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "def mostrar_resultados(y_test, pred_y):\n",
    "    conf_matrix = confusion_matrix(y_test, pred_y)\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    sns.heatmap(conf_matrix, xticklabels=2, yticklabels=2, annot=True, fmt=\"d\");\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.ylabel('True class')\n",
    "    plt.xlabel('Predicted class')\n",
    "    plt.show()\n",
    "    print (classification_report(y_test, pred_y))\n",
    "mostrar_resultados(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos ahora con los datos balanceados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "os =  RandomOverSampler(sampling_strategy='minority')\n",
    "X_train_res, y_train_res = os.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:30:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[10:31:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:37:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[10:37:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:42:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[10:42:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:48:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[10:48:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:00:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:00:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:12:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:12:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:24:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:24:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:30:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:36:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:37:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:43:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:43:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:56:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:56:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:08:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[12:08:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:20:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[12:20:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, random_state=None,\n",
       "                                     reg_alpha=None, reg_lambda=None,\n",
       "                                     scale_pos_weight=None, subsample=None,\n",
       "                                     tree_method=None, validate_parameters=None,\n",
       "                                     verbosity=None),\n",
       "             param_grid={'learning_rate': [0.05, 0.1],\n",
       "                         'n_estimators': [100, 200], 'nthreads': [1],\n",
       "                         'objective': ['binary:logistic']},\n",
       "             scoring='recall')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=200, n_jobs=4, nthreads=1, num_parallel_tree=1,\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_xgb_balanced = clf.best_estimator_\n",
    "best_xgb_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7909354329204142"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_preds_balanced = best_xgb_balanced.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86    404477\n",
      "           1       0.03      0.75      0.07      4784\n",
      "\n",
      "    accuracy                           0.75    409261\n",
      "   macro avg       0.52      0.75      0.46    409261\n",
      "weighted avg       0.98      0.75      0.85    409261\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_preds_balanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86    404477\n",
      "           1       0.03      0.75      0.07      4784\n",
      "\n",
      "    accuracy                           0.75    409261\n",
      "   macro avg       0.52      0.75      0.46    409261\n",
      "weighted avg       0.98      0.75      0.85    409261\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "def mostrar_resultados(y_test, pred_y):\n",
    "    conf_matrix = confusion_matrix(y_test, pred_y)\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    sns.heatmap(conf_matrix, xticklabels=2, yticklabels=2, annot=True, fmt=\"d\");\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.ylabel('True class')\n",
    "    plt.xlabel('Predicted class')\n",
    "    plt.show()\n",
    "    print (classification_report(y_test, pred_y))\n",
    "mostrar_resultados(y_test, y_preds_balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_f1 = GridSearchCV(xgb, parameters, cv=3, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:46:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[12:46:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:52:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[12:52:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:00:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13:00:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:07:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13:07:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:19:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13:19:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:30:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13:31:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:43:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13:43:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:48:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13:48:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:54:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13:54:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:01:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:01:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:16:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:16:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:31:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:32:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:46:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"nthreads\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:47:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, random_state=None,\n",
       "                                     reg_alpha=None, reg_lambda=None,\n",
       "                                     scale_pos_weight=None, subsample=None,\n",
       "                                     tree_method=None, validate_parameters=None,\n",
       "                                     verbosity=None),\n",
       "             param_grid={'learning_rate': [0.05, 0.1],\n",
       "                         'n_estimators': [100, 200], 'nthreads': [1],\n",
       "                         'objective': ['binary:logistic']},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_f1.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgb_f1 = clf_f1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7769189156307266"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_f1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_preds_f1_balanced = best_xgb_f1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86    404477\n",
      "           1       0.03      0.75      0.07      4784\n",
      "\n",
      "    accuracy                           0.75    409261\n",
      "   macro avg       0.52      0.75      0.46    409261\n",
      "weighted avg       0.98      0.75      0.85    409261\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_preds_f1_balanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = clf_f1.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.49860382, 0.5013962 ],\n",
       "       [0.6150206 , 0.38497943],\n",
       "       [0.38316894, 0.61683106],\n",
       "       ...,\n",
       "       [0.5824162 , 0.41758385],\n",
       "       [0.17397201, 0.826028  ],\n",
       "       [0.25591785, 0.74408215]], dtype=float32)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_xgb_f1.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49860382, 0.5013962 ],\n",
       "       [0.6150206 , 0.38497943],\n",
       "       [0.38316894, 0.61683106],\n",
       "       ...,\n",
       "       [0.5824162 , 0.41758385],\n",
       "       [0.17397201, 0.826028  ],\n",
       "       [0.25591785, 0.74408215]], dtype=float32)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_f1.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds_f1_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resul = pd.DataFrame()\n",
    "resul['prob0'] = prob[:,0]\n",
    "resul['prob1'] = prob[:,1]\n",
    "resul['prediction'] = y_preds_f1_balanced\n",
    "resul['real'] = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob0</th>\n",
       "      <th>prob1</th>\n",
       "      <th>prediction</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.946354</td>\n",
       "      <td>0.053646</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.807220</td>\n",
       "      <td>0.192780</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.267888</td>\n",
       "      <td>0.732112</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.690786</td>\n",
       "      <td>0.309214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.657692</td>\n",
       "      <td>0.342308</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409256</th>\n",
       "      <td>0.387238</td>\n",
       "      <td>0.612762</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409257</th>\n",
       "      <td>0.822449</td>\n",
       "      <td>0.177551</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409258</th>\n",
       "      <td>0.775101</td>\n",
       "      <td>0.224899</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409259</th>\n",
       "      <td>0.885936</td>\n",
       "      <td>0.114064</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409260</th>\n",
       "      <td>0.971914</td>\n",
       "      <td>0.028086</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>409261 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           prob0     prob1  prediction  real\n",
       "0       0.946354  0.053646           0     0\n",
       "1       0.807220  0.192780           0     0\n",
       "2       0.267888  0.732112           1     0\n",
       "3       0.690786  0.309214           0     0\n",
       "4       0.657692  0.342308           0     0\n",
       "...          ...       ...         ...   ...\n",
       "409256  0.387238  0.612762           1     0\n",
       "409257  0.822449  0.177551           0     0\n",
       "409258  0.775101  0.224899           0     0\n",
       "409259  0.885936  0.114064           0     0\n",
       "409260  0.971914  0.028086           0     0\n",
       "\n",
       "[409261 rows x 4 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000413656234741"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resul[(resul['prediction']!=resul['real'])&(resul['prediction']==1)]['prob1'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob0</th>\n",
       "      <th>prob1</th>\n",
       "      <th>prediction</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.199717</td>\n",
       "      <td>0.800283</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.149973</td>\n",
       "      <td>0.850027</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.206438</td>\n",
       "      <td>0.793562</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.262895</td>\n",
       "      <td>0.737105</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>0.100727</td>\n",
       "      <td>0.899273</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408716</th>\n",
       "      <td>0.419817</td>\n",
       "      <td>0.580183</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408724</th>\n",
       "      <td>0.301682</td>\n",
       "      <td>0.698318</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408948</th>\n",
       "      <td>0.299335</td>\n",
       "      <td>0.700665</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409137</th>\n",
       "      <td>0.243555</td>\n",
       "      <td>0.756445</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409226</th>\n",
       "      <td>0.392780</td>\n",
       "      <td>0.607220</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3577 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           prob0     prob1  prediction  real\n",
       "26      0.199717  0.800283           1     1\n",
       "115     0.149973  0.850027           1     1\n",
       "127     0.206438  0.793562           1     1\n",
       "177     0.262895  0.737105           1     1\n",
       "285     0.100727  0.899273           1     1\n",
       "...          ...       ...         ...   ...\n",
       "408716  0.419817  0.580183           1     1\n",
       "408724  0.301682  0.698318           1     1\n",
       "408948  0.299335  0.700665           1     1\n",
       "409137  0.243555  0.756445           1     1\n",
       "409226  0.392780  0.607220           1     1\n",
       "\n",
       "[3577 rows x 4 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resul_TP = resul[(resul['prediction']==resul['real'])&(resul['prediction']==1)]\n",
    "resul_TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob0</th>\n",
       "      <th>prob1</th>\n",
       "      <th>prediction</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.267888</td>\n",
       "      <td>0.732112</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.328611</td>\n",
       "      <td>0.671389</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.374719</td>\n",
       "      <td>0.625281</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.438219</td>\n",
       "      <td>0.561781</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.279152</td>\n",
       "      <td>0.720848</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409235</th>\n",
       "      <td>0.279152</td>\n",
       "      <td>0.720848</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409238</th>\n",
       "      <td>0.315620</td>\n",
       "      <td>0.684380</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409254</th>\n",
       "      <td>0.468849</td>\n",
       "      <td>0.531151</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409255</th>\n",
       "      <td>0.339902</td>\n",
       "      <td>0.660098</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409256</th>\n",
       "      <td>0.387238</td>\n",
       "      <td>0.612762</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99165 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           prob0     prob1  prediction  real\n",
       "2       0.267888  0.732112           1     0\n",
       "7       0.328611  0.671389           1     0\n",
       "9       0.374719  0.625281           1     0\n",
       "11      0.438219  0.561781           1     0\n",
       "18      0.279152  0.720848           1     0\n",
       "...          ...       ...         ...   ...\n",
       "409235  0.279152  0.720848           1     0\n",
       "409238  0.315620  0.684380           1     0\n",
       "409254  0.468849  0.531151           1     0\n",
       "409255  0.339902  0.660098           1     0\n",
       "409256  0.387238  0.612762           1     0\n",
       "\n",
       "[99165 rows x 4 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resul_FP = resul[(resul['prediction']!=resul['real'])&(resul['prediction']==1)]\n",
    "resul_FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-82-541be9ef417c>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  resul_TP['50-60']=np.where((resul_TP['prob1']>=0.5) & (resul_TP['prob1']<0.6),1,0)\n",
      "<ipython-input-82-541be9ef417c>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  resul_TP['60-70']=np.where((resul_TP['prob1']>=0.6) & (resul_TP['prob1']<0.7),1,0)\n",
      "<ipython-input-82-541be9ef417c>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  resul_TP['70-80']=np.where((resul_TP['prob1']>=0.7) & (resul_TP['prob1']<0.8),1,0)\n",
      "<ipython-input-82-541be9ef417c>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  resul_TP['80-90']=np.where((resul_TP['prob1']>=0.8) & (resul_TP['prob1']<0.9),1,0)\n",
      "<ipython-input-82-541be9ef417c>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  resul_TP['90-100']=np.where(resul_TP['prob1']>=0.9,1,0)\n",
      "<ipython-input-82-541be9ef417c>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  resul_FP['50-60']=np.where((resul_FP['prob1']>=0.5) & (resul_FP['prob1']<0.6),1,0)\n",
      "<ipython-input-82-541be9ef417c>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  resul_FP['60-70']=np.where((resul_FP['prob1']>=0.6) & (resul_FP['prob1']<0.7),1,0)\n",
      "<ipython-input-82-541be9ef417c>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  resul_FP['70-80']=np.where((resul_FP['prob1']>=0.7) & (resul_FP['prob1']<0.8),1,0)\n",
      "<ipython-input-82-541be9ef417c>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  resul_FP['80-90']=np.where((resul_FP['prob1']>=0.8) & (resul_FP['prob1']<0.9),1,0)\n",
      "<ipython-input-82-541be9ef417c>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  resul_FP['90-100']=np.where(resul_FP['prob1']>=0.9,1,0)\n"
     ]
    }
   ],
   "source": [
    "resul_TP['50-60']=np.where((resul_TP['prob1']>=0.5) & (resul_TP['prob1']<0.6),1,0)\n",
    "resul_TP['60-70']=np.where((resul_TP['prob1']>=0.6) & (resul_TP['prob1']<0.7),1,0)\n",
    "resul_TP['70-80']=np.where((resul_TP['prob1']>=0.7) & (resul_TP['prob1']<0.8),1,0)\n",
    "resul_TP['80-90']=np.where((resul_TP['prob1']>=0.8) & (resul_TP['prob1']<0.9),1,0)\n",
    "resul_TP['90-100']=np.where(resul_TP['prob1']>=0.9,1,0)\n",
    "\n",
    "resul_FP['50-60']=np.where((resul_FP['prob1']>=0.5) & (resul_FP['prob1']<0.6),1,0)\n",
    "resul_FP['60-70']=np.where((resul_FP['prob1']>=0.6) & (resul_FP['prob1']<0.7),1,0)\n",
    "resul_FP['70-80']=np.where((resul_FP['prob1']>=0.7) & (resul_FP['prob1']<0.8),1,0)\n",
    "resul_FP['80-90']=np.where((resul_FP['prob1']>=0.8) & (resul_FP['prob1']<0.9),1,0)\n",
    "resul_FP['90-100']=np.where(resul_FP['prob1']>=0.9,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prop(x):\n",
    "    return sum(x)*100/len(x)\n",
    "\n",
    "TP = resul_TP.groupby(['real']).agg({'50-60':['sum',prop],\n",
    "                               '60-70':['sum',prop],\n",
    "                               '70-80':['sum',prop],\n",
    "                               '80-90':['sum',prop],\n",
    "                               '90-100':['sum',prop]})\n",
    "\n",
    "FP = resul_FP.groupby(['real']).agg({'50-60':['sum',prop],\n",
    "                               '60-70':['sum',prop],\n",
    "                               '70-80':['sum',prop],\n",
    "                               '80-90':['sum',prop],\n",
    "                               '90-100':['sum',prop]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">50-60</th>\n",
       "      <th colspan=\"2\" halign=\"left\">60-70</th>\n",
       "      <th colspan=\"2\" halign=\"left\">70-80</th>\n",
       "      <th colspan=\"2\" halign=\"left\">80-90</th>\n",
       "      <th colspan=\"2\" halign=\"left\">90-100</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>prop</th>\n",
       "      <th>sum</th>\n",
       "      <th>prop</th>\n",
       "      <th>sum</th>\n",
       "      <th>prop</th>\n",
       "      <th>sum</th>\n",
       "      <th>prop</th>\n",
       "      <th>sum</th>\n",
       "      <th>prop</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>real</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>568</td>\n",
       "      <td>15.879228</td>\n",
       "      <td>740</td>\n",
       "      <td>20.687727</td>\n",
       "      <td>1011</td>\n",
       "      <td>28.263908</td>\n",
       "      <td>1070</td>\n",
       "      <td>29.913335</td>\n",
       "      <td>188</td>\n",
       "      <td>5.255801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     50-60            60-70            70-80            80-90             \\\n",
       "       sum       prop   sum       prop   sum       prop   sum       prop   \n",
       "real                                                                       \n",
       "1      568  15.879228   740  20.687727  1011  28.263908  1070  29.913335   \n",
       "\n",
       "     90-100            \n",
       "        sum      prop  \n",
       "real                   \n",
       "1       188  5.255801  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">50-60</th>\n",
       "      <th colspan=\"2\" halign=\"left\">60-70</th>\n",
       "      <th colspan=\"2\" halign=\"left\">70-80</th>\n",
       "      <th colspan=\"2\" halign=\"left\">80-90</th>\n",
       "      <th colspan=\"2\" halign=\"left\">90-100</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>prop</th>\n",
       "      <th>sum</th>\n",
       "      <th>prop</th>\n",
       "      <th>sum</th>\n",
       "      <th>prop</th>\n",
       "      <th>sum</th>\n",
       "      <th>prop</th>\n",
       "      <th>sum</th>\n",
       "      <th>prop</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>real</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34491</td>\n",
       "      <td>34.781425</td>\n",
       "      <td>27389</td>\n",
       "      <td>27.619624</td>\n",
       "      <td>23186</td>\n",
       "      <td>23.381233</td>\n",
       "      <td>13017</td>\n",
       "      <td>13.126607</td>\n",
       "      <td>1082</td>\n",
       "      <td>1.091111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      50-60             60-70             70-80             80-90             \\\n",
       "        sum       prop    sum       prop    sum       prop    sum       prop   \n",
       "real                                                                           \n",
       "0     34491  34.781425  27389  27.619624  23186  23.381233  13017  13.126607   \n",
       "\n",
       "     90-100            \n",
       "        sum      prop  \n",
       "real                   \n",
       "0      1082  1.091111  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3577"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resul_TP.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección de la probalidad de corte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez localizado el modelo adecuado y realizado un análisis de cuándo tenemos más falsos positivos, buscamos una opción para mejorar la presición del modelo modificando la probabilidad de corte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_custom(modelo,X,prob=0.5):\n",
    "    y_prob = modelo.predict_proba(X)[:,1]\n",
    "    y_pred = np.where(y_prob>=prob,1,0)\n",
    "    return y_pred\n",
    "\n",
    "def arg_model(y_pred,y_real):\n",
    "    resul = pd.DataFrame()\n",
    "    resul['prediction'] = y_pred\n",
    "    resul['real'] = np.array(y_real)\n",
    "\n",
    "    #Cálculo de FalsePositive, TruePositive, FalseNegative, TrueNegative\n",
    "    FP = resul[(resul['prediction']!=resul['real'])&(resul['prediction']==1)].shape[0]\n",
    "    TP = resul[(resul['prediction']==resul['real'])&(resul['prediction']==1)].shape[0]\n",
    "    FN = resul[(resul['prediction']!=resul['real'])&(resul['prediction']==0)].shape[0]\n",
    "    TN = resul[(resul['prediction']==resul['real'])&(resul['prediction']==0)].shape[0]\n",
    "    \n",
    "    #Cálculo de los argumentos\n",
    "    precision = TP / (TP+FP)\n",
    "    recall = TP / (TP+FN)\n",
    "    f1 = 2 * recall * precision / (recall + precision)\n",
    "    return precision,recall,f1\n",
    "    \n",
    "def max_score_model(modelo,X,y,prob=[0.5],arg='precision'):\n",
    "    #inicialización del máximo\n",
    "    p = prob[0]\n",
    "    arg_max = 0\n",
    "    for i in prob:\n",
    "        y_pred = predict_custom(modelo, X, prob=i)\n",
    "        precision,recall,f1 = arg_model(y_pred,y)\n",
    "        if (arg=='precision')&(precision>arg_max):\n",
    "            p = i\n",
    "            arg_max = precision\n",
    "        elif (arg=='recall')&(recall>arg_max):\n",
    "            p = i\n",
    "            arg_max = recall\n",
    "        elif (arg=='f1')&(f1>arg_max):\n",
    "            p = i\n",
    "            arg_max = f1\n",
    "    return p,arg_max\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 0.034815362753304394, Recall: 0.747700668896321, f1: 0.06653274556851366\n"
     ]
    }
   ],
   "source": [
    "i = 0.5\n",
    "y_pred = predict_custom(modelo=clf_f1, X=X_test, prob=i)\n",
    "precision,recall,f1 = arg_model(y_pred,y_test)\n",
    "\n",
    "print('Precisión: '+str(precision)+', Recall: '+str(recall)+', f1: '+str(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 0.039371575932594154, Recall: 0.6925167224080268, f1: 0.07450720221295162\n"
     ]
    }
   ],
   "source": [
    "i = 0.55\n",
    "y_pred = predict_custom(modelo=clf_f1, X=X_test, prob=i)\n",
    "precision,recall,f1 = arg_model(y_pred,y_test)\n",
    "\n",
    "print('Precisión: '+str(precision)+', Recall: '+str(recall)+', f1: '+str(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 0.03026443809870352, Recall: 0.7997491638795987, f1: 0.058321837153113884\n"
     ]
    }
   ],
   "source": [
    "i = 0.45\n",
    "y_pred = predict_custom(modelo=clf_f1, X=X_test, prob=i)\n",
    "precision,recall,f1 = arg_model(y_pred,y_test)\n",
    "\n",
    "print('Precisión: '+str(precision)+', Recall: '+str(recall)+', f1: '+str(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 0.02965351881784267, Recall: 0.8091555183946488, f1: 0.05721041936079808\n"
     ]
    }
   ],
   "source": [
    "i = 0.44\n",
    "y_pred = predict_custom(modelo=clf_f1, X=X_test, prob=i)\n",
    "precision,recall,f1 = arg_model(y_pred,y_test)\n",
    "\n",
    "print('Precisión: '+str(precision)+', Recall: '+str(recall)+', f1: '+str(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.45, 0.7978232189973615)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, X_valid, y_test, y_valid = train_test_split(X_test, y_test, test_size=0.2, random_state=1)\n",
    "max_score_model(clf_f1,X_test,y_test,prob=[0.45,0.5,0.55,0.6],arg='recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javier.ruibal\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 0.03020117641243636, Recall: 0.7997382198952879, f1: 0.05820433436532507\n"
     ]
    }
   ],
   "source": [
    "y_pred_valid = predict_custom(modelo=clf_f1, X=X_valid, prob=0.45)\n",
    "precision,recall,f1 = arg_model(y_pred_valid,y_valid)\n",
    "\n",
    "\n",
    "print('Precisión: '+str(precision)+', Recall: '+str(recall)+', f1: '+str(f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
